{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import ndarray\n",
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data as load_fashion_mnist\n",
    "from tensorflow.keras.datasets.mnist import load_data as load_mnist\n",
    "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.utils.layer_utils import count_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_portable_path() -> Path:\n",
    "    \"\"\"Utility for getting a sensible working directory whether running as a script or in Colab\"\"\"\n",
    "    try:\n",
    "        outdir = Path(__file__).resolve().parent\n",
    "        return outdir\n",
    "    except NameError:\n",
    "        print(\"Possible use of Colab detected. Attempting to exploit `globals()`...\")\n",
    "    try:\n",
    "        outdir = Path(globals()[\"_dh\"][0]).resolve()\n",
    "        return outdir\n",
    "    except KeyError:\n",
    "        print(\"Colab not detected.\")\n",
    "        print(\"Defaulting to current working directory for files.\")\n",
    "        return Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible use of Colab detected. Attempting to exploit `globals()`...\n",
      "Possible use of Colab detected. Attempting to exploit `globals()`...\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = get_portable_path() / \"outputs\"\n",
    "DATADIR = get_portable_path() / \"dataset\"\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we build a naive (inefficient) convolutional autoencoder by simply stacking convolutions\n",
    "# in the encoding path, and then stacking the appropriate number of transposed convolutions in the\n",
    "# decoding path. More efficient architectures would employ strided convolutions and/or MaxPooling\n",
    "# layers, but this make determining the number and size of the transposed convolutions *much* more\n",
    "# difficult, especially if you want to easily be able to adjust depth. So we settle on the simple\n",
    "# architecture below.\n",
    "class ConvAutoencoder(Model):\n",
    "    def __init__(self, depth: int = 8) -> None:\n",
    "        super().__init__()\n",
    "        conv_args = dict(filters=4, kernel_size=3, activation=\"relu\")  # save space / repetition\n",
    "\n",
    "        # Build an encoding path\n",
    "        self.encoder = Sequential()\n",
    "        self.encoder.add(Conv2D(data_format=\"channels_last\", input_shape=IMG_SHAPE, **conv_args))\n",
    "        self.encoder.add(BatchNorm())\n",
    "        for _ in range(depth - 1):\n",
    "            self.encoder.add(Conv2D(**conv_args))\n",
    "            self.encoder.add(BatchNorm())\n",
    "\n",
    "        # this line also forces a bottleneck of sorts, in that it forces the code to have 1 channel\n",
    "        # this is why the encoded representation can be plotted as a black and white images. Note\n",
    "        # that if you changed below to `filters=3`, then you could see what coloured feature maps\n",
    "        # would look like.\n",
    "        self.encoder.add(Conv2D(padding=\"same\", **conv_args))\n",
    "\n",
    "        # Build a decoding path\n",
    "        encodeshape = self.encoder.output_shape[1:]\n",
    "        self.decoder = Sequential()\n",
    "        self.decoder.add(Conv2DTranspose(padding=\"same\", input_shape=encodeshape, **conv_args))\n",
    "        self.encoder.add(BatchNorm())\n",
    "        for _ in range(depth - 1):\n",
    "            self.decoder.add(Conv2DTranspose(**conv_args))\n",
    "            self.encoder.add(BatchNorm())\n",
    "        self.decoder.add(Conv2DTranspose(filters=1, kernel_size=3, activation=\"linear\"))\n",
    "\n",
    "    def call(self, x: Tensor) -> Tensor:\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train = ImageDataGenerator(rescale = (1./255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3141 files belonging to 3 classes.\n",
      "Using 2827 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 10:37:45.719272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-30 10:37:46.482239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-30 10:37:46.483226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-30 10:37:46.494866: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-30 10:37:46.502000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-30 10:37:46.502749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-30 10:37:46.503328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-30 10:37:53.324293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-30 10:37:53.325056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-30 10:37:53.325074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-11-30 10:37:53.325724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-30 10:37:53.325794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2749 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  DATADIR,\n",
    "  validation_split=0.1,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(300, 300),\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (/home/dalon/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:301742)",
      "at S.execute (/home/dalon/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:300732)",
      "at S.start (/home/dalon/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:296408)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/dalon/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (/home/dalon/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "dir(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8300dcbfad1446d93b6069ae3a38010429a4e246246e20501cd878e3a8643006"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('csci340': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
